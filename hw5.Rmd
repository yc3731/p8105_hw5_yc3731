---
title: "p8105_hw5_yc3731"
author: "Yue Chen"
date: "11/17/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Import dataset.
```{r}
homecide = read.csv("./data/homicide-data.csv")
```

Describe dataset.

The raw dataset has `r nrow(homecide)` observations and `r ncol(homecide)` columns. 
Variables in the dataset include `r names(homecide)`. 

Create a new variable.
```{r}
homecide = 
  homecide %>%
  mutate(city_state = str_c(city, ", ", state))
```

Summarize within cities to obtain the total number of homicides and the number of unsolved homicides.
```{r}
homecide_df =
  homecide %>%
  mutate(
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved", 
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"       ~ "solved"
    )
  ) %>%
  select(city_state, resolved) %>%
  filter(city_state != "Tulsa, AL")

aggregate_df = 
  homecide_df %>%
  group_by(city_state) %>%
  summarise(
    hom_total = n(), 
    hom_unsolved = sum(resolved == "unsolved")
  )
```

For the city of Baltimore, MD, estimate the proportion of homicides that are unsolved.
```{r}
prop.test(
  aggregate_df %>%
    filter(city_state == "Baltimore, MD") %>%
    pull(hom_unsolved), 
  aggregate_df %>%
    filter(city_state == "Baltimore, MD") %>%
    pull(hom_total)
  )%>%
    broom::tidy()
```

Iterate the test for each city in the dataset.
```{r}
results_df = 
  aggregate_df %>%
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)), 
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>%
  select(-prop_tests) %>%
  unnest(tidy_tests) %>%
  select(city_state, estimate, conf.low, conf.high)
```

Create a plot that shows the estimates and CIs for each city.
```{r}
results_plot = 
  results_df %>%
  ggplot(aes(x = reorder(city_state, estimate), y = estimate)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 80, hjust = 1)) +
  labs(
    title = "Estimates and CIs of unsolved homecides for each city", 
    x = "city", 
    y = "proportions of unsolved homecides"
  )

results_plot
```

## Problem 2

Import and tidy data.
```{r}
study_data = 
  tibble(file_name = list.files(path = "./data/data")) %>%
  mutate(name = map(.x = str_c("./data/data/", file_name), ~read_csv(.x))) %>%
  unnest() %>%
  separate(file_name, into = c("arm", "id"), sep = "_", remove = F) %>%
  gather(key = week, value = observation, week_1:week_8) %>%
  mutate(
    week = str_replace(week, "week_", ""),
    file_name = str_replace(file_name, ".csv", ""), 
    id = str_replace(id, ".csv", "")
  )
```

Make a spaghetti plot showing observations on each subject over time.
```{r}
spaghetti_plot = 
  study_data %>%
    ggplot(
      aes(x = week, y = observation, group = file_name, col = arm)
    ) + 
    geom_line() +
    labs(
      title = "Observations on each subject over time",
      x = "week", 
      y = "observation"
    ) + 
    theme(legend.position = "bottom")

spaghetti_plot
```

In general, patients in control arm have lower weekly observations than patients in experimental arm.
Some patients in control and experiment arms have similar weekly observations.

## Problem 3

Conduct a simulation.
```{r}
set.seed(1)

sim_mean_sd = function(sample_size, mu, sigma = 5) {
  
  sim_data =
    tibble(
      x = rnorm(n = sample_size, mean = mu, sd = sigma)
    )
  
  sim_data %>%
    t.test(mu = 0, conf.level = 0.95) %>%
    broom::tidy() %>%
    select(estimate, p.value)
}

```

Generate 5000 datasets.
```{r}
sim_results_0 = 
  rerun(5000, sim_mean_sd(sample_size = 30, mu = 0)) %>%
  bind_rows() 
```

Repeat for other values of mu.
```{r}
sim_results = 
  tibble(
    mu = c(0, 1, 2, 3, 4, 5, 6)
  ) %>%
  mutate(
    output_lists = map(.x = mu, ~rerun(5000, sim_mean_sd(30, mu = .x))), 
    estimate_df = map(output_lists, bind_rows)
  ) %>%
  select(-output_lists) %>%
  unnest(estimate_df)
```

Make a plot showing the proportion of times the null was rejected.
```{r}
results_df = 
  sim_results %>%
  group_by(mu) %>%
  mutate(
    decision = case_when(
      p.value < 0.05 ~ "reject", 
      p.value > 0.05 ~ "fail to reject"
    )
  )

power_plot = 
  results_df %>%
  group_by(mu) %>%
  summarise(
    reject = sum(p.value < 0.05),
    count = n(),
    proportion = reject/count
  ) %>%
  ggplot(
    aes(x = mu, y = proportion)
  ) + 
  geom_point() +
  geom_line() + 
  labs(
    title = "Proportions of times when null was rejected under different effect size", 
    x = "effect size", 
    y = "proportion"
  ) + 
  theme(plot.title = element_text(hjust = 0.5))
  
```
Greater effect size is associated with higher power. When effect size is 4, 5, or 6, power is similar.

Make a plot showing the average estimate of mu and true value of mu.
```{r}
avg_true_plot = 
  results_df %>%
  group_by(mu) %>%
  summarise(
    avg_est = mean(estimate)
  ) %>%
  ggplot(
    aes(x = mu, y = avg_est)
  ) +
  geom_point() +
  geom_line() +
  labs(
    title = "The average estimates of mu vs. true values of mu",
    x = "true value of mu", 
    y = "average estimate of mu"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
```

Make a plot showing the average estimate of mu only in samples for which the null was rejected and the true value of mu.
```{r}
reject_plot = 
  results_df %>%
  group_by(mu) %>%
  filter(decision == "reject") %>%
  summarise(
    avg_est = mean(estimate)
  ) %>%
  ggplot(
    aes(x = mu, y = avg_est)
  ) + 
  geom_point() +
  geom_line() +
  labs(
    title = "Samples for which the null was rejected",
    x = "true values of mu", 
    y = "average estimate of mu"
  ) + 
  theme(plot.title = element_text(hjust = 0.5))
  
```
When effect size is large (greater or equal to 3), the sample average of mu is approximately equal to the true value of mu. When effect size is smaller (0, 1, or 2), the average estimation of mu seems to be off. 

When sample size is constant, it is easier to detect a great effect size with precision while it would be more difficult to detect a small effect size.
